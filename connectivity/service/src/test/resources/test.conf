pekko {
  loggers = ["org.apache.pekko.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "org.apache.pekko.event.slf4j.Slf4jLoggingFilter"

  # for log messages during the actor system is starting up and shutting down:
  stdout-loglevel = "WARNING"

  log-config-on-start = off

  http {
    client.idle-timeout = Inf
  }
}

// dead letters log disabled because actors are being killed all the time
pekko.log-dead-letters = 0
pekko.cluster.jmx.multi-mbeans-in-same-jvm = on
pekko.cluster.roles = ["thing-event-aware", "live-signal-aware", "acks-aware", "policy-announcement-aware",
  "blocked-namespaces-aware", "connectivity"]

ditto {
  extensions {
    connection-priority-provider-factory = org.eclipse.ditto.connectivity.service.messaging.persistence.UsageBasedPriorityProviderFactory
    client-actor-props-factory = org.eclipse.ditto.connectivity.service.messaging.DefaultClientActorPropsFactory
    hono-connection-factory = "org.eclipse.ditto.connectivity.service.messaging.hono.DefaultHonoConnectionFactory"
    message-mapper-extension = "org.eclipse.ditto.connectivity.service.mapping.NoOpMessageMapperExtension"
    signal-enrichment-provider {
      extension-class = org.eclipse.ditto.connectivity.service.mapping.DefaultConnectivitySignalEnrichmentProvider
      extension-config = {
        cache.enabled = false
        ask-timeout = 2s
      }
    }
    connection-enforcer-actor-props-factory = org.eclipse.ditto.connectivity.service.enforcement.NoOpEnforcerActorPropsFactory
    custom-connectivity-command-interceptor-provider = org.eclipse.ditto.connectivity.service.messaging.validation.NoOpConnectivityCommandInterceptorProvider
    pre-enforcer-provider {
      extension-class = org.eclipse.ditto.policies.enforcement.pre.PreEnforcerProvider
      extension-config = {
        pre-enforcers = [
          "org.eclipse.ditto.policies.enforcement.pre.CommandWithOptionalEntityPreEnforcer"
        ]
      }
    }
    snapshot-adapter = {
      extension-class = "org.eclipse.ditto.connectivity.service.messaging.persistence.ConnectionMongoSnapshotAdapter"
    }
    ditto-headers-validator = {
      extension-class = org.eclipse.ditto.edge.service.headers.DefaultDittoHeadersValidator
      extension-config {
        max-bytes = 5k
        max-auth-subjects = 100
      }
    }

    message-mapper-provider {
      extension-class = "org.eclipse.ditto.connectivity.service.mapping.MessageMapperProvider"
      extension-config {
        message-mappers = [
          "org.eclipse.ditto.connectivity.service.mapping.DittoMessageMapper"
          "org.eclipse.ditto.connectivity.service.mapping.ConnectionStatusMessageMapper"
          "org.eclipse.ditto.connectivity.service.mapping.ImplicitThingCreationMessageMapper"
          "org.eclipse.ditto.connectivity.service.mapping.javascript.JavaScriptMessageMapperRhino"
          "org.eclipse.ditto.connectivity.service.mapping.NormalizedMessageMapper"
          "org.eclipse.ditto.connectivity.service.mapping.RawMessageMapper"
          "org.eclipse.ditto.connectivity.service.mapping.UpdateTwinWithLiveResponseMessageMapper"
          "org.eclipse.ditto.connectivity.service.mapping.test.MockMapper"
          "org.eclipse.ditto.connectivity.service.messaging.AddHeaderMessageMapper"
          "org.eclipse.ditto.connectivity.service.messaging.FaultyMessageMapper"
          "org.eclipse.ditto.connectivity.service.messaging.DroppingMessageMapper"
          "org.eclipse.ditto.connectivity.service.messaging.DuplicatingMessageMapper"
        ]
      }
    }
  }
  mapping-strategy.implementation = "org.eclipse.ditto.connectivity.api.ConnectivityMappingStrategies"

  ddata {
    subscription-write-consistency = "local"
    subscription-delay = "0s"
  }

  pubsub {
    restart-delay = 1s
    update-interval = 100ms // increase this value to simulate slow systems
    seed = "dummy-seed"
  }

  mongodb {
    uri = "mongodb://localhost:27017/connectivity"
  }
  connectivity {

    default-config-provider = true

    user-indicated-errors = [
      {exceptionName: "org.apache.qpid.jms.provider.exceptions.ProviderSecurityException", messagePattern: ".*"}
    ]

    hono {
        base-uri = "tcp://localhost:9922"
        validate-certificates = false
        ca = "-----BEGIN CERTIFICATE-----\n<trusted certificate>\n-----END CERTIFICATE-----"
        sasl-mechanism = PLAIN
        bootstrap-servers = "tcp://server1:port1,tcp://server2:port2,tcp://server3:port3"
        username = test_username
        password = test_password_w/special_char
    }

    connection {
      // allow localhost in unit tests
      blocked-hostnames = ""

      # Number of sources per connection
      max-source-number = 4
      # Number of targets per connection
      max-target-number = 4

      client-actor-restarts-before-escalation = 3

      supervisor {
        exponential-backoff {
          min = 1s
          max = 5s
          random-factor = 1.0
        }
      }

      snapshot {
        threshold = 5
      }

      activity-check {
        # the interval of how long to keep an "inactive" Connection in memory:
        inactive-interval = 0 # keep active indefinitely

        # the interval of how long to keep a deleted Connection in memory:
        deleted-interval = 1s
      }

      flush-pending-responses-timeout = 0s

      kafka {
        consumer {
          metric-collecting-interval = 5s
          init-timeout-seconds = 3

          throttling.enabled = true

          pekko-connectors = ${pekko.kafka.consumer}
          pekko-connectors = {
            default.key.serde = "org.apache.kafka.common.serialization.Serdes$StringSerde" # default:	org.apache.kafka.common.serialization.Serdes$ByteArraySerde
            default.value.serde = "org.apache.kafka.common.serialization.Serdes$StringSerde" # default:	org.apache.kafka.common.serialization.Serdes$ByteArraySerde
            kafka-clients {
              enable.auto.commit = true
              retries = 0
              request {
                timeout {
                  ms = 10000
                }
              }
            }
          }
        }

        producer {
          queue-size = 39
          parallelism = 3
          min-backoff = 3s
          max-backoff = 30s
          random-factor = 0.2
          init-timeout-seconds = 3

          pekko-connectors = ${pekko.kafka.producer}
          pekko-connectors {
            kafka-clients {
              connections.max.idle.ms = 543210
              reconnect.backoff {
                ms = 500
                max {
                  ms = 10000
                }
              }
            }
          }
        }

      }

      pubsub {
        consumer {
            init-timeout-seconds = 3
        }

        producer {
            init-timeout-seconds = 3
        }
      }

      amqp10 {
        consumer {
          throttling {
            enabled = true
            interval = 100ms
            limit = 1
          }
        }
        publisher {
          max-queue-size = 2
          parallelism = 2
        }

        producer-cache-size = 10
        global-send-timeout = 120s

        hmac-algorithms {
          az-sasl = "org.eclipse.ditto.connectivity.service.messaging.signing.AzSaslSigningFactory"
        }

        include "backoff-test"
      }

      amqp091 {
        publisher {
          pending-ack-ttl = 1d
        }
      }

      http-push {
        max-queue-size = 100
        proxy {
          enabled = false
          hostname = ""
          port = 0
          username = ""
          password = ""
        }
        hmac-algorithms {
          aws4-hmac-sha256 = "org.eclipse.ditto.connectivity.service.messaging.httppush.AwsRequestSigningFactory"
          az-monitor-2016-04-01 =
            "org.eclipse.ditto.connectivity.service.messaging.httppush.AzMonitorRequestSigningFactory"
          az-sasl = "org.eclipse.ditto.connectivity.service.messaging.signing.AzSaslSigningFactory"
        }
      }

      mqtt {
        reconnect-for-redelivery = true
        separate-publisher-client = true

        reconnect {
          backoff {

          }
        }
      }

    }

    mapping {
      buffer-size = 10
      parallelism = 1
      javascript {
        maxScriptSizeBytes = 50000 # 50kB
        maxScriptExecutionTime = 30000ms
        maxScriptStackDepth = 25
        commonJsModulePath = "./target/test-classes/unpacked-test-webjars"
      }
      mapper-limits {
        max-source-mappers = 9
        max-mapped-inbound-messages = 8
        max-target-mappers = 7
        max-mapped-outbound-messages = 6
      }
    }

    persistence-ping {
      # initial delay for reconnecting the connections after the ReconnectActor has been started.
      initial-delay = 0s
      initial-delay = ${?RECONNECT_INITIAL_DELAY}
      # interval for trying to reconnect all started connections.
      interval = 10m
      interval = ${?RECONNECT_INTERVAL}

      # used to throttle the recovery of connections, so that not all connections are recovered at the same time
      rate {
        frequency = 1s
        frequency = ${?RECONNECT_RATE_FREQUENCY}
        entities = 2
        entities = ${?RECONNECT_RATE_ENTITIES}
      }
    }

    client {
      connecting-min-timeout = 5s
      connecting-max-timeout = 5s
      connecting-max-tries = 10
      disconnecting-max-timeout = 3s
      disconnect-announcement-timeout = 1s
      testing-timeout = 5s
      min-backoff = 100ms
      max-backoff = 400ms
    }

    monitoring {

      logger {
        successCapacity = 3
        successCapacity = ${?CONNECTIVITY_LOGGER_SUCCESS_CAPACITY}
        failureCapacity = 10
        failureCapacity = ${?CONNECTIVITY_LOGGER_FAILURE_CAPACITY}
        maxLogSizeBytes = 1000
        maxLogSizeBytes = ${?CONNECTIVITY_LOGGER_MAX_LOG_SIZE_BYTES}
        logDuration = 10m
        logDuration = ${?CONNECTIVITY_LOGGER_LOG_DURATION}
        loggingActiveCheckInterval = 1m
      }

      counter {}
    }

  }
}

pekko {
  loggers = ["org.apache.pekko.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "org.apache.pekko.event.slf4j.Slf4jLoggingFilter"

  # for log messages during the actor system is starting up and shutting down:
  stdout-loglevel = "WARNING"

  log-config-on-start = off

  actor {
    provider = cluster
    enable-additional-serialization-bindings = on

    # this is only intended for testing.
    serialize-messages = off
    serialize-creators = off

    debug {
      lifecycle = on
    }

    default-dispatcher {
      fork-join-executor {
        parallelism-min = 4
        parallelism-factor = 3.0
        parallelism-max = 32
        parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
      }
    }

    serializers {
      bson = "org.eclipse.ditto.internal.utils.test.mongo.BsonDocumentSerializer"
      json = "org.eclipse.ditto.internal.utils.cluster.JsonJsonifiableSerializer"
      cbor = "org.eclipse.ditto.internal.utils.cluster.CborJsonifiableSerializer"
      cbor-json-value = "org.eclipse.ditto.internal.utils.cluster.CborJsonValueSerializer"
      jackson-cbor = "org.apache.pekko.serialization.jackson.JacksonCborSerializer"
    }

    serialization-bindings {
      "org.bson.BsonDocument" = bson
      # Serialize Jsonifiable events with custom JSON serializer:
      "org.eclipse.ditto.base.model.json.Jsonifiable" = cbor
      "org.eclipse.ditto.base.model.exceptions.DittoRuntimeException" = cbor
      "org.eclipse.ditto.base.api.devops.signals.commands.DevOpsCommandResponse" = json # to ensure readability
      "org.eclipse.ditto.json.JsonValue" = cbor-json-value
      "org.eclipse.ditto.internal.utils.cluster.PekkoJacksonCborSerializable" = jackson-cbor
    }
  }

  extensions = [
    "org.apache.pekko.cluster.pubsub.DistributedPubSub"
  ]

  remote {
    log-remote-lifecycle-events = on
    artery {
      enabled = on
      transport = tcp
      canonical {
        # InetAddress.getLocalHost.getHostAddress is used if empty
        hostname = "127.0.0.1"
        hostname = ${?REMOTE_HOSTNAME}
        port = 0
        port = ${?REMOTE_PORT}
      }
      bind {
        hostname = ${?BIND_HOSTNAME}
        port = ${?BIND_REMOTE_PORT}
      }
    }
  }

  cluster {
    # Disable legacy metrics in pekko-cluster.
    metrics.enabled = off

    # enable weakly up feature to allow members to join even if some members are unreachable
    allow-weakly-up-members = on

    # required for pekko-management-cluster-bootstrap (to be more robust):
    shutdown-after-unsuccessful-join-seed-nodes = 40s

    sharding {
      state-store-mode = ddata
      use-dispatcher = "sharding-dispatcher"

      role = "connectivity"
    }

    distributed-data {
      # set gossip interval and notify-subscribers-interval to low values so that pubsub delay is minimal
      gossip-interval = 50ms
      notify-subscribers-interval = 50ms
    }
  }

  http {
    server {
      server-header = "" # default: pekko-http/${pekko.http.version}
      max-connections = 4096 # default: 1024
      backlog = 100 # default: 100

      parsing {
        max-uri-length = 8k # default: 2k
        max-content-length = 10m # default: 8m
        illegal-header-warnings = off # default: on
        error-logging-verbosity = simple # default: full
        uri-parsing-mode = relaxed # default: strict
      }
    }

    host-connection-pool {
      # The maximum number of open requests accepted into the pool across all
      # materializations of any of its client flows.
      # Protects against (accidentally) overloading a single pool with too many client flow materializations.
      # Note that with N concurrent materializations the max number of open request in the pool
      # will never exceed N * max-connections * pipelining-limit.
      # Must be a power of 2 and > 0!
      max-open-requests = 1024 # default: 32

      # The time after which an idle connection pool (without pending requests)
      # will automatically terminate itself. Set to `infinite` to completely disable idle timeouts.
      idle-timeout = 60s # default: 30s
    }
  }

  test {
    # factor by which to scale timeouts during tests, e.g. to account for shared
    # build system load
    timefactor = 1.0

    # duration of EventFilter.intercept waits after the block is finished until
    # all required messages are received
    filter-leeway = 3s

    # duration to wait in expectMsg and friends outside of within() block
    # by default
    single-expect-default = 3s

    # The timeout that is added as an implicit by DefaultTimeout trait
    default-timeout = 5s

    calling-thread-dispatcher {
      type = org.apache.pekko.testkit.CallingThreadDispatcherConfigurator
    }
  }
}

pekko.persistence {
  journal.auto-start-journals = [
    "pekko-contrib-mongodb-persistence-connection-journal"
  ]
  snapshot-store.auto-start-snapshot-stores = [
    "pekko-contrib-mongodb-persistence-connection-snapshots"
  ]
}

pekko-contrib-mongodb-persistence-connection-journal {
  class = "org.apache.pekko.persistence.inmemory.journal.InMemoryAsyncWriteJournal"
  plugin-dispatcher = "connection-persistence-dispatcher"

  ask-timeout = 10s

  event-adapters {
    mongodbobject = "org.eclipse.ditto.connectivity.service.messaging.persistence.ConnectivityMongoEventAdapter"
  }

  event-adapter-bindings {
    "org.eclipse.ditto.base.model.signals.events.Event" = mongodbobject
    "org.bson.BsonValue" = mongodbobject
  }
}

pekko-contrib-mongodb-persistence-connection-snapshots {
  class = "org.apache.pekko.persistence.inmemory.snapshot.InMemorySnapshotStore"
  plugin-dispatcher = "connection-persistence-dispatcher"

  ask-timeout = 10s
}

pekko-contrib-mongodb-persistence-reconnect-journal {
  class = "org.apache.pekko.persistence.inmemory.journal.InMemoryAsyncWriteJournal"
  plugin-dispatcher = "reconnect-persistence-dispatcher"

  ask-timeout = 10s

  event-adapters {
    mongodbobject = "org.eclipse.ditto.connectivity.service.messaging.persistence.ConnectivityMongoEventAdapter"
  }

  event-adapter-bindings {
    "org.eclipse.ditto.base.model.signals.events.Event" = mongodbobject
    "org.bson.BsonValue" = mongodbobject
  }
}

pekko-contrib-mongodb-persistence-reconnect-snapshots {
  class = "org.apache.pekko.persistence.inmemory.snapshot.InMemorySnapshotStore"
  plugin-dispatcher = "reconnect-persistence-dispatcher"

  ask-timeout = 10s
}

connection-persistence-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 4
    parallelism-factor = 3.0
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  throughput = 5
}

reconnect-persistence-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 4
    parallelism-factor = 3.0
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  throughput = 5
}

message-mapping-processor-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 4.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 64
  }
  throughput = 5
}

jms-connection-handling-dispatcher {
  type = PinnedDispatcher
  executor = "thread-pool-executor"
}

signal-enrichment-cache-dispatcher {
  type = PinnedDispatcher
  executor = "thread-pool-executor"
}

http-push-connection-dispatcher {
  type = PinnedDispatcher
  executor = "thread-pool-executor"
}

kafka-consumer-dispatcher {
  type = PinnedDispatcher
  executor = "thread-pool-executor"
}

kafka-producer-dispatcher {
  type = PinnedDispatcher
  executor = "thread-pool-executor"
}

blocked-namespaces-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  throughput = 5
}


pekko.connectors.google {

  credentials {
    # Used to build a list of default scopes from each of the modules, don't override
    default-scopes = ${?pekko.connectors.google.credentials.default-scopes} []
    # Override to specify custom scopes
    scopes = ${pekko.connectors.google.credentials.default-scopes}

    # Options: application-default, service-account, compute-engine, none
    # application-default first tries service-account then compute-engine
    provider = application-default

    service-account {

      # Config values have first priority, otherwise look for credentials file
      project-id = ""
      client-email = ""
      private-key = ""

      # Resolves a path to the well-known credentials file
      # See https://github.com/googleapis/google-auth-library-java/blob/master/oauth2_http/java/com/google/auth/oauth2/DefaultCredentialsProvider.java#L237
      path = ${user.home}/.config
      path = ${?APPDATA} # Windows-only
      path = ${pekko.connectors.google.credentials.service-account.path}/gcloud
      path = ${?CLOUDSDK_CONFIG}
      path = ${pekko.connectors.google.credentials.service-account.path}/application_default_credentials.json
      path = ${?GOOGLE_APPLICATION_CREDENTIALS}

      # Always required regardless of where credentials are read from
      scopes = ${pekko.connectors.google.credentials.scopes}
    }

    # Timeout for blocking call during settings initialization to compute engine metadata server
    compute-engine.timeout = 1s

    user-access {
      project-id = ""
      client-id = ""
      client-secret = ""
      refresh-token = ""

      # Resolves a path to the well-known credentials file
      # See https://github.com/googleapis/google-auth-library-java/blob/master/oauth2_http/java/com/google/auth/oauth2/DefaultCredentialsProvider.java#L237
      path = ${user.home}/.config
      path = ${?APPDATA} # Windows-only
      path = ${pekko.connectors.google.credentials.user-access.path}/gcloud
      path = ${?CLOUDSDK_CONFIG}
      path = ${pekko.connectors.google.credentials.user-access.path}/application_default_credentials.json
      path = ${?GOOGLE_APPLICATION_CREDENTIALS}
    }

    none {
      project-id = "<no-project-id>"
      token = "<no-token>"
    }
  }

  # Standard query parameters for all Google APIs sent with every request
  user-ip = ""
  quota-user = ""
  pretty-print = false

  # The minimum size of a chunk, must be a multiple of 256 KiB. See https://github.com/googleapis/java-core/issues/86
  upload-chunk-size = 15 MiB

  # The retry settings for requests to Google APIs
  # Defaults from https://github.com/googleapis/python-api-core/blob/master/google/api_core/retry.py#L72
  retry-settings {
    max-retries = 10
    min-backoff = 1 second
    max-backoff = 1 minute
    random-factor = 0.2
  }

  # An address of a proxy that will be used for all connections using HTTP CONNECT tunnel.
  # forward-proxy {
  #   scheme = "https"
  #   host = "proxy"
  #   port = 8080
  #   credentials {
  #     username = "username"
  #     password = "password"
  #   }
  #   trust-pem = "/path/to/file.pem"
  # }

}